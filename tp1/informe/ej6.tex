\section{Ejercicio 6}

%El artículo llama nubes o recursos a los servidores, yo a veces me confundo y pongo un nombre u otro, revisar si es confuso
En el paper en cuestión, los autores intentan encontrar un algoritmo de scheduling optimizado para el Cloud Computing. En particular, quieren encontrar un algoritmo que, teniendo en cuenta las singularidades del modelo de Cloud Computing, como lo es el estar orientado a trabajo cooperativo, pero con usuarios con requerimientos diferentes, optimice el tiempo en que cada tarea se encuentra en estado de espera (Ready). En particular, los autores observan como problema que las tareas de alta granularidad pasan gran tiempo en espera.
Los autores analizan los esquemas de scheduling usados en Cloud Computing, en particular Task Grouping y priorización con conciencia de ancho de banda (Prioritization with Bandwidth Awareness). En el primero, consiste en agrupar tareas similares y programarlas en grupo, en particular basándose en el nivel de granularidad, agrupando tareas altamente granulares para simplificar el uso de recursos. En el segundo, el scheduler toma en cuenta el ancho de banda disponible en cada ronda para agrupar y programar las tareas con el objetivo de reducir la latencia de comunicación entre tareas y el tiempo de espera de las mismas.

El algoritmo que proponen los autores se basa en integrar estos dos algoritmos, junto con un Scheduler SJF. Teniendo en cuenta que el agrupamiento tradicional no contempla el ancho de banda de red o el tamaño de los archivos de tarea, el algoritmo propuesto por los autores comienza por la capacidad de procesamiento de cada nube, ordenándolas descendentemente en base a sus MIPS. Luego, con el objetivo de reducir el tiempo de espera de cada tarea, el scheduler agrupa las tareas en base a la granularidad, primero tareas altamente granulares, de acuerdo con la capacidad de procesamiento de la primera nube, y envía la tarea agrupada a la misma, siguiendo de igual forma con las demás.	
En detalle, existen cuatro fases. La primera consta de la inicialización de los recursos y los datos de entrada. Los autores informan que por utilizar la función aleatoria para generar los valores de los mismos (tamaño de archivos, recursos de los servidores, requerimientos de cada tarea) en el momento de la experimentación, cada uno de estos sigue la distribución uniforme. En la segunda fase se ordenan las tareas en base a sus demandas y características y, los recursos en primera instancia según ancho de banda para reducir la latencia de red y en segundo lugar por capacidad de procesamiento. Luego, en la tercera fase se agrupan las tareas y se envían a los servidores ya priorizados como se explicó anteriormente. En cada nube, el grupo de tareas se considera como una sola tarea de baja granularidad y así es ejecutada. En la cuarta y última fase, se aplica un algoritmo SJF en cada servidor para reducir aún más el tiempo de espera de cada tarea.

Para poder analizar el comportamiento del sheduler, los autores decidieron experimentar sobre un simulador (CloudSim) que les permitió modelar todos los servicios necesarios. Se utilizó su set de herramientas para simular los distintos ambientes de ejecución, y los recursos se representaron como parámetros, como lo fuera el ID del recurso, los elementos de procesamiento, MIPS,  ancho de banda y RAM, entre otros. 
En el experimento se utilizaron 10 recursos (servidores) de tiempo compartido y cada uno es alojado en una máquina con características diferentes (en particular, ancho de banda y capacidad de procesamiento, que son los factores que los autores toman para hacer el estudio, todos los servidores tienen 2GB de RAM y el mismo costo por ancho de banda). La capacidad computacional de cada nube se estableció en $200 MIPS \pm 30\%$ .

Cada tarea tiene asociados sus requerimientos de cómputo, el tamaño de los datos de entrada y salida, y otros parámetros. Cada una simula aplicaciones basadas en la nube, como lo es la transferencia de contenido, interacción social, y otras. Para generar las tareas se utilizó una distribución gaussiana con un mínimo de 1 millón de instrucciones y una función aleatoria para generar el tamaño de los archivos de entrada y salida. El tamaño del archivo de tarea y del archivo de salida de la misma se hicieron aleatoriamente en el rango de $100 bytes \pm 30\%$  cada uno, la cantidad de tareas varió de 1000 a 7000 con cambios de a 1000 tareas y la granularidad fue de 10s a 30s con pasos de a 5s.
