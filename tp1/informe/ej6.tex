\section{Ejercicio 6}

\subsection{Enunciado}
A partir del artículo:

\begin{itemize}
\item Jia Ru and Jack Keung. \textit{An Empirical Investigation on the Simulation of Priority and Shortest-Job-First Scheduling for Cloud-based Software Systems}, 2013 22nd Australian Conference on Software Engineering
\end{itemize}

Responda:

\begin{enumerate}[a)]
\item ¿Qué problema están intentando resolver los autores?
\item ¿Qué algoritmo generan para resolverlo?
\item Explicar brevemente las pruebas realizadas
\end{enumerate}

\subsection{Resolución}
%El artículo llama nubes o recursos a los servidores, yo a veces me confundo y pongo un nombre u otro, revisar si es confuso
En el paper en cuestión, los autoires intentan encontrar un algoritmo de scheduiling opitimizado para el Cloud Computing. En particular, quieren encontrar un algoritmo que, teniendo en cuenta las sigularidades del modelo de Cloud Computing, como lo es el estar orientado a trabajo cooperartivo, pero con usuarios con requerimientos diferentes, optimice el tiempo en que cada tarea se encuentra en estado de espera (Ready). En particular, los autores observan como problema que las tareas de alta granularidad pasan gran tiempo en espera.
Los autores analizan los esquemas de scheduling usados en cloud computing, en particular Task Grouping y piroirización con conciencia de anchoi de banda (Prioritization  with Bandwidth Awareness). En el primero, explican que consiste en agrupar tareas similares y programarlas en grupo, en particular, basándose en el nivel de granularidad, agrupando tareas altamente granulares para simplificar el uso de recursos. En el segundo, el scheduler, explican, toma en cuenta el ancho de banda disponible en cada ronda para agrupar y programar las tareas con el objetivo de reducir la latencia de comunicación entre tareas y el tiempo de espera de las mismas.

El algoritmo que proponen los autores se basa en integrar estos dos algoritmos, junto con un Scheduler SJF. Teniendo en cuenta que el agrupamiento tradicional no tiene en cuenta el ancho de banda de red o el tamaño de los archivos de tarea, el algoritmo propuesto por los autores comienza por la capacidad de procesamiento de cada nube, ordenándolas descendentemente en base a sus MIPS. Luego, con el objetivo de reducir el tiempo de espera de cada tarea, el scheduler agrupa las tareas en base a la granularidad, primero tareas altamente granulares, de acuerdo con la capacidad de procesamiento de la primera nube, y envía la tarea agrupada a la misma, siguiendo de igual forma con las demás.	
En detalle, existen cuatro fases. La primera consta de la inicialización de inicialización de los recursos y los datos de entrada. Los autrores informan que por utilizar la función aleatoria para generar los valores de los mismos (tamaño de archivos, recursos de los servidores, requerimientos de cada tarea) en el momento de la experimentación, cada uno de estos sigue la distribución uniforme. En la segunda fase se ordenan las tareas en base a sus demandas y características y los recursos, en primera instancia según ancho de banda para reducir la latencia de red y en segundo lugar por capacidad de procesamiento. Luego, en la tercera fase se agrupan las tareas y se envían a los servidores ya priorizados como se explicó anteriormente. En cada nube, el grupo de tareas se considera como una sola tarea de baja granularidad y así es ejecutada. En la cuarta y última fase, se aplica un algoritmo SJF en cada servidor para reducir aún más el tiempo de espera de cada tarea.

Para poder analizar el comportamiento del sheduler, los autores decidieron experimentar sobre un simulador (CloudSim) que les permitió modelar todos los servicios necesarios. Se utilizó su set de herramientas para simular los distintos ambientes de ejecución, y los recursos se representaron como parametros, como lo fuera el ID del recurso, los elementos de procesamiento, MIPS,  ancho de banda y RAM, entre otros. 
En el experimento se utilizaron 10 recursos (servidores) de tiempo compartido y cada uno es alojado en una máquina con características diferentes (en particular, ancho de banda y capacidad de procesamiento, que son los factores que los autores toman para hcer el estudio, todos los servidores tienen 2GB de RAM y el mismo costo por ancho de banda). La capacidad computacional de cada nube se estableció en $200 MIPS \pm 30\%$ .

Cada tarea tiene asociuados sus requerimientos de cómputo, el tamaño de los datos de entrada y salida y otros parámetros. Cada una simula aplicaciones basadas en la nube, como lo es la transferencia de contenido, interacción social, y otras. Para genererar las tareas se utilizó una distribución gausiana con un mínimo de 1 millón de intsrucciones y una funcion aleatoria para generar el tamaño de los archivos de entrada y salida. El tamaño del arrchivo de tarea y del archivo de salida de la misma se hicieron aleatoriamente en el rango de $100 bytes \pm 30\%$  cada uno, la cantidad de tareas varió de 1000 a 7000 con cambios de a 1000 tareas y la granularidad fue de 10 s a 30 s con pasos de a 5 s.